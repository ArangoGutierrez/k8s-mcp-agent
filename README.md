# k8s-gpu-mcp-server

**Just-in-Time SRE Diagnostic Agent for NVIDIA GPU Clusters on Kubernetes**

[![Go Version](https://img.shields.io/badge/Go-1.25+-00ADD8?style=flat&logo=go)](https://go.dev/)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
[![CI Status](https://github.com/ArangoGutierrez/k8s-gpu-mcp-server/workflows/CI/badge.svg)](https://github.com/ArangoGutierrez/k8s-gpu-mcp-server/actions)
[![GitHub Issues](https://img.shields.io/github/issues/ArangoGutierrez/k8s-gpu-mcp-server)](https://github.com/ArangoGutierrez/k8s-gpu-mcp-server/issues)
[![GitHub Stars](https://img.shields.io/github/stars/ArangoGutierrez/k8s-gpu-mcp-server?style=social)](https://github.com/ArangoGutierrez/k8s-gpu-mcp-server)
[![MCP](https://img.shields.io/badge/MCP-2025--06--18-purple)](https://modelcontextprotocol.io/)

---

## Overview

`k8s-gpu-mcp-server` is an **ephemeral diagnostic agent** that provides surgical, 
real-time NVIDIA GPU hardware introspection for Kubernetes clusters via the 
[Model Context Protocol (MCP)](https://modelcontextprotocol.io/). 

Unlike traditional monitoring systems, this agent is designed for **AI-assisted 
troubleshooting** by SREs debugging complex hardware failures that standard 
Kubernetes APIs cannot detect.

### âœ¨ Key Features

- ğŸ¯ **On-Demand Diagnostics** - Agent runs only during `kubectl exec` sessions
- ğŸ”Œ **Stdio Transport** - JSON-RPC 2.0 over `kubectl debug` SPDY tunneling
- ğŸ” **Deep Hardware Access** - Direct NVML integration for GPU diagnostics
- ğŸ¤– **AI-Native** - Built for Claude Desktop, Cursor, and MCP-compatible hosts
- ğŸ”’ **Secure by Default** - Read-only operations with explicit operator mode
- âš¡ **Production Ready** - Real Tesla T4 testing, 74/74 tests passing

---

## ğŸš€ Quick Start

### One-Line Installation

```bash
# Using npx (recommended)
npx k8s-gpu-mcp-server@latest

# Or install globally
npm install -g k8s-gpu-mcp-server
```

### Use with Cursor

Add to your Cursor MCP configuration:

```json
{
  "mcpServers": {
    "k8s-gpu": {
      "command": "npx",
      "args": ["-y", "k8s-gpu-mcp-server@latest"]
    }
  }
}
```

### Use with Claude Desktop

Add to `~/Library/Application Support/Claude/claude_desktop_config.json`:

```json
{
  "mcpServers": {
    "k8s-gpu": {
      "command": "npx",
      "args": ["-y", "k8s-gpu-mcp-server@latest"]
    }
  }
}
```

### Install from Source

```bash
# Clone and build
git clone https://github.com/ArangoGutierrez/k8s-gpu-mcp-server.git
cd k8s-gpu-mcp-server
make agent

# Test with mock GPUs (no hardware required)
cat examples/gpu_inventory.json | ./bin/agent --nvml-mode=mock

# Test with real GPU (requires NVIDIA driver)
cat examples/gpu_inventory.json | ./bin/agent --nvml-mode=real
```

### Deploy to Kubernetes

```bash
# Deploy with Helm (RuntimeClass mode - recommended)
helm install k8s-gpu-mcp-server ./deployment/helm/k8s-gpu-mcp-server \
  --namespace gpu-diagnostics --create-namespace

# Find agent pod on target node
NODE_NAME=<node-name>
POD=$(kubectl get pods -n gpu-diagnostics \
  -l app.kubernetes.io/name=k8s-gpu-mcp-server \
  --field-selector spec.nodeName=$NODE_NAME \
  -o jsonpath='{.items[0].metadata.name}')

# Start diagnostic session
kubectl exec -it -n gpu-diagnostics $POD -- /agent --mode=read-only
```

> **Note:** GPU access requires `runtimeClassName: nvidia` configured by
> GPU Operator or nvidia-ctk. For clusters without RuntimeClass, use fallback:
> `--set gpu.runtimeClass.enabled=false --set gpu.resourceRequest.enabled=true`

### Use with Claude Desktop

Add to your Claude Desktop configuration:

```json
{
  "mcpServers": {
    "k8s-gpu-agent": {
      "command": "kubectl",
      "args": ["debug", "node/gpu-node-5", "--image=...", "--", "/agent"]
    }
  }
}
```

Then ask Claude: *"What's the temperature of the GPUs on node gpu-node-5?"*

ğŸ“– **[Full Quick Start Guide â†’](docs/quickstart.md)**

---

## ğŸ“Š Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     kubectl debug      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Claude     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚  K8s Node      â”‚
â”‚   Desktop    â”‚   SPDY Stdio Tunnel     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚  â”‚  Agent   â”‚  â”‚
       â–²                                 â”‚  â”‚  (stdio) â”‚  â”‚
       â”‚         JSON-RPC 2.0             â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
       â”‚         MCP Protocol             â”‚       â”‚        â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”  â”‚
                                          â”‚   â”‚  NVML  â”‚  â”‚
                                          â”‚   â”‚  API   â”‚  â”‚
                                          â”‚   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â”‚
                                          â”‚       â”‚       â”‚
                                          â”‚   GPU 0...N   â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Design Principles:**
- **"Syringe Pattern"**: Ephemeral injection, zero idle footprint
- **Stdio-Only**: No network listeners, firewall-friendly
- **Interface Abstraction**: Testable, flexible, portable

ğŸ“– **[Architecture Documentation â†’](docs/architecture.md)**

---

## ğŸ› ï¸ Available Tools

| Tool | Description | Status |
|------|-------------|--------|
| `get_gpu_inventory` | Hardware inventory + telemetry | âœ… Available |
| `analyze_xid_errors` | Parse GPU XID error codes from kernel logs | âœ… Available |
| `get_gpu_health` | GPU health monitoring with scoring | âœ… Available |
| `get_gpu_telemetry` | Real-time metrics | ğŸš§ M2 Phase 3 |
| `inspect_topology` | NVLink/PCIe topology | ğŸš§ M2 Phase 4 |
| `kill_gpu_process` | Terminate GPU process | ğŸš§ M3 (Operator) |
| `reset_gpu` | GPU reset | ğŸš§ M3 (Operator) |

ğŸ“– **[MCP Usage Guide â†’](docs/mcp-usage.md)**

---

## ğŸ“ˆ Project Status

### Current Milestone: [M2: Hardware Introspection](https://github.com/ArangoGutierrez/k8s-gpu-mcp-server/milestone/2)
**Due:** January 17, 2026  
**Progress:** Phase 1 Complete (Real NVML âœ…)

### Completed Milestones
- âœ… [M1: Foundation & API](https://github.com/ArangoGutierrez/k8s-gpu-mcp-server/milestone/1) - Completed Jan 3, 2026
  - Go module scaffolding
  - MCP stdio server
  - Mock NVML implementation
  - Comprehensive CI/CD

### Recent Updates
- **Jan 4, 2026**: GPU health monitoring tool (`get_gpu_health`) merged
- **Jan 3, 2026**: XID error analysis tool (`analyze_xid_errors`) merged
- **Jan 3, 2026**: Real NVML integration complete, tested on Tesla T4
- **Jan 3, 2026**: 74/74 tests passing, 5/5 integration tests on real GPU

ğŸ“Š **[View All Milestones â†’](https://github.com/ArangoGutierrez/k8s-gpu-mcp-server/milestones)**

---

## ğŸ§ª Testing

### Unit Tests (No GPU Required)

```bash
make test                   # Run all unit tests (74/74 passing)
make coverage               # Generate coverage report
make coverage-html          # View coverage in browser
```

### Integration Tests (Requires GPU)

```bash
make test-integration       # Run on GPU hardware
# Or manually:
go test -tags=integration -v ./pkg/nvml/
```

**Latest Test Results on Tesla T4:**
```
âœ“ TestRealNVML_Integration
  - GPU: Tesla T4 (15GB)
  - Temperature: 29Â°C
  - Power: 13.9W
  - Utilization: 0% (idle)

âœ“ 5/5 integration tests passing
âœ“ 74/74 total tests passing
```

---

## ğŸ—ï¸ Build

```bash
# Build for local platform
make agent

# Build for Linux (with real NVML)
CGO_ENABLED=1 GOOS=linux GOARCH=amd64 make agent

# Build container image
make image

# Multi-arch release builds
make dist
```

**Binary Sizes:**
- Mock mode: **4.3MB** (CGO disabled)
- Real mode: **7.9MB** (CGO enabled)

---

## ğŸ“¦ Installation

### Using npm (Recommended)

```bash
# Run directly with npx
npx k8s-gpu-mcp-server@latest

# Or install globally
npm install -g k8s-gpu-mcp-server
```

### From Source

```bash
git clone https://github.com/ArangoGutierrez/k8s-gpu-mcp-server.git
cd k8s-gpu-mcp-server
make agent
sudo mv bin/agent /usr/local/bin/k8s-gpu-mcp-server
```

### Using Go

```bash
go install github.com/ArangoGutierrez/k8s-gpu-mcp-server/cmd/agent@latest
```

### Container Image (Coming in M3)

```bash
docker pull ghcr.io/arangogutierrez/k8s-gpu-mcp-server:latest
```

---

## ğŸ¤ Contributing

We welcome contributions! Please see our [Development Guide](DEVELOPMENT.md)
for details.

### Quick Contribution Guide

1. Check [open issues](https://github.com/ArangoGutierrez/k8s-gpu-mcp-server/issues)
2. Fork and create feature branch: `git checkout -b feat/my-feature`
3. Make changes, add tests
4. Run checks: `make all`
5. Commit with DCO: `git commit -s -S -m "feat(scope): description"`
6. Open PR with labels and milestone

ğŸ“– **[Full Development Guide â†’](DEVELOPMENT.md)**

---

## ğŸ“š Documentation

- **[Quick Start Guide](docs/quickstart.md)** - Get running in 5 minutes
- **[Architecture](docs/architecture.md)** - System design and components
- **[MCP Usage](docs/mcp-usage.md)** - How to consume the MCP server
- **[Development Guide](DEVELOPMENT.md)** - Contributing guidelines
- **[Examples](examples/)** - Sample JSON-RPC requests

---

## ğŸ”§ Technology Stack

- **Language**: Go 1.25+ (latest stable)
- **MCP Protocol**: [mcp-go v0.43.2](https://github.com/mark3labs/mcp-go)
- **GPU Library**: [go-nvml v0.13.0-1](https://github.com/NVIDIA/go-nvml)
- **Testing**: [testify v1.10.0](https://github.com/stretchr/testify)
- **Container**: Distroless Debian 12 (coming in M3)

---

## ğŸ¯ Use Cases

### 1. Debugging Stuck Training Jobs

```
SRE: "Why is the training job on node-5 stuck?"
Claude â†’ k8s-gpu-mcp-server â†’ Detects XID 48 (ECC Error)
Claude: "Node-5 has uncorrectable memory errors. Drain immediately."
```

### 2. Thermal Management

```
SRE: "Are any GPUs thermal throttling?"
Claude â†’ k8s-gpu-mcp-server â†’ Checks temps and throttle status
Claude: "GPU 3 is at 86Â°C and thermal throttling. Check cooling."
```

### 3. Topology Validation

```
SRE: "Is NVLink properly configured for multi-GPU training?"
Claude â†’ k8s-gpu-mcp-server â†’ Inspects NVLink topology
Claude: "All 8 GPUs connected via NVLink, 600GB/s bandwidth."
```

### 4. Zombie Process Hunting

```
SRE: "GPU memory is full but no pods are running"
Claude â†’ k8s-gpu-mcp-server â†’ Lists GPU processes
Claude: "Found zombie process PID 12345 using 8GB. Kill it?"
```

---

## ğŸ† Achievements

- âœ… **Go 1.25** - Latest Go version
- âœ… **Real NVML** - Tested on Tesla T4
- âœ… **74/74 Tests** - 100% passing with race detector
- âœ… **Zero Lint Issues** - Clean codebase
- âœ… **7.9MB Binary** - 84% under 50MB target
- âœ… **MCP 2025-06-18** - Latest protocol version
- âœ… **Production Ready** - Used on real hardware

---

## ğŸ“„ License

Apache License 2.0 - See [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- [NVIDIA NVML](https://developer.nvidia.com/nvidia-management-library-nvml) - GPU Management Library
- [Model Context Protocol](https://modelcontextprotocol.io/) - MCP Specification
- [mcp-go](https://github.com/mark3labs/mcp-go) - MCP Go Implementation
- [Anthropic Claude](https://www.anthropic.com/claude) - AI Assistant
- [Cursor](https://cursor.sh/) - AI-Powered IDE

---

## ğŸ“ Contact

**Maintainer:** [@ArangoGutierrez](https://github.com/ArangoGutierrez)  
**Issues:** [GitHub Issues](https://github.com/ArangoGutierrez/k8s-gpu-mcp-server/issues)  
**Discussions:** [GitHub Discussions](https://github.com/ArangoGutierrez/k8s-gpu-mcp-server/discussions)

---

<div align="center">

**â­ Star us on GitHub â€” it helps!**

[Report Bug](https://github.com/ArangoGutierrez/k8s-gpu-mcp-server/issues/new?template=bug_report.yml) Â· 
[Request Feature](https://github.com/ArangoGutierrez/k8s-gpu-mcp-server/issues/new?template=feature_request.yml) Â· 
[View Roadmap](https://github.com/ArangoGutierrez/k8s-gpu-mcp-server/milestones)

</div>
